{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Walk Through Ensemble Models\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. Please check the pdf file for more details.*\n",
    "\n",
    "In this exercise you will:\n",
    "\n",
    "- get to know a useful package **pandas** for data analysis/preprocessing\n",
    "- implement **decision tree** and apply it to a Titanic dataset\n",
    "- implement a whole bunch of **ensemble methods**, including **random forest, and adaboost**, and apply them to a Titanic dataset\n",
    "\n",
    "Please note that **YOU CANNOT USE ANY MACHINE LEARNING PACKAGE SUCH AS SKLEARN** for any homework, unless you are asked to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# some basic imports\n",
    "from scipy import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first do some data preprocessing\n",
    "\n",
    "Here we use [pandas](https://pandas.pydata.org/) to do data preprocessing. Pandas is a very popular and handy package for data science or machine learning. You can also refer to this official guide for pandas: [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (1047, 11) test shape: (262, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hays, Miss. Margaret Bechstein</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C54</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Holm, Mr. John Fredrik Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C 7075</td>\n",
       "      <td>6.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Hansen, Mr. Claus Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>350026</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived                              Name     Sex   Age  SibSp  \\\n",
       "0       1         1    Hays, Miss. Margaret Bechstein  female  24.0      0   \n",
       "1       3         0  Holm, Mr. John Fredrik Alexander    male  43.0      0   \n",
       "2       3         0           Hansen, Mr. Claus Peter    male  41.0      2   \n",
       "\n",
       "   Parch  Ticket     Fare Cabin Embarked  \n",
       "0      0   11767  83.1583   C54        C  \n",
       "1      0  C 7075   6.4500   NaN        S  \n",
       "2      0  350026  14.1083   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read titanic train and test data\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "print(\"train shape: {} test shape: {}\".format(train.shape, test.shape))\n",
    "# Showing overview of the train dataset\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deal with missing values and transform to discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from: https://www.kaggle.com/dmilla/introduction-to-decision-trees-titanic-dataset\n",
    "full_data = [train, test]\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "\n",
    "# Remove all NULLS in the Age column\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    # Next line has been improved to avoid warning\n",
    "    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_elements = ['Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived  Sex  Age  Parch  Fare  Embarked  Has_Cabin  FamilySize  \\\n",
       "0       1         1    0    1      0     3         1          1           1   \n",
       "1       3         0    1    2      0     0         0          0           1   \n",
       "2       3         0    1    2      0     1         0          0           3   \n",
       "3       3         0    1    1      0     0         2          0           1   \n",
       "4       2         0    1    2      0     1         0          0           1   \n",
       "\n",
       "   IsAlone  Title  \n",
       "0        1      4  \n",
       "1        1      1  \n",
       "2        0      1  \n",
       "3        1      1  \n",
       "4        1      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the good thing of pd.DataFrame is that you can keep the column names along with the data, which can be beneficial for many case.\n",
    "\n",
    "Another good thing is that pd.DataFrame can be converted to np.array implicitely.\n",
    "\n",
    "Also, pd provides a lot of useful data manipulating methods for your convenience, though we may not use them in this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1047, 10), test: (262, 10)\n"
     ]
    }
   ],
   "source": [
    "X = train.drop(['Survived'], axis=1)\n",
    "y = train[\"Survived\"]\n",
    "X_test = test.drop(['Survived'], axis=1)\n",
    "y_test = test[\"Survived\"]\n",
    "print(\"train: {}, test: {}\".format(X.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_gt, y_pred):\n",
    "    return np.sum(y_gt == y_pred) / y_gt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived: 0.3878, Not Survivied: 0.6122\n"
     ]
    }
   ],
   "source": [
    "print(\"Survived: {:.4f}, Not Survivied: {:.4f}\".format(y.sum() / len(y), 1 - y.sum() / len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex  Age  Parch  Fare  Embarked  Has_Cabin  FamilySize  IsAlone  \\\n",
      "0       1    0    1      0     3         1          1           1        1   \n",
      "\n",
      "   Title  \n",
      "0      4  \n"
     ]
    }
   ],
   "source": [
    "print (X[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Now it's your turn to do some real coding. Please implement the decision tree model in **decision_tree.py**. The PDF file provides some hints for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Accuracy on train set: 0.8787010506208214\n",
      "Accuracy on test set: 0.7900763358778626\n"
     ]
    }
   ],
   "source": [
    "def calc_height(d):\n",
    "    now = 0\n",
    "    if type(d) == dict:\n",
    "        for t in list(d.values())[0].values():\n",
    "            now = max(now, calc_height(t))\n",
    "    return now + 1\n",
    "\n",
    "from decision_tree import DecisionTree\n",
    "\n",
    "# Plot the decision tree to get an intuition about how it makes decision\n",
    "#plt.figure(figsize=(10, 5))\n",
    "#dt.show()\n",
    "\n",
    "dt = DecisionTree(criterion='entropy', max_depth=10, min_samples_leaf=1, sample_feature=False)\n",
    "dt.fit(X, y)\n",
    "y_train_pred = dt.predict(X)\n",
    "print (calc_height(dt._tree))\n",
    "print(\"Accuracy on train set: {}\".format(accuracy(y, dt.predict(X))))\n",
    "print(\"Accuracy on test set: {}\".format(accuracy(y_test, dt.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy 1 5 0.7992937733392289\n",
      "entropy 1 6 0.799393209786271\n",
      "entropy 1 7 0.7983865402979309\n",
      "entropy 1 8 0.8013493436089073\n",
      "entropy 1 9 0.7966667279789232\n",
      "entropy 1 10 0.7993397742309168\n",
      "entropy 2 5 0.8006302964652257\n",
      "entropy 2 6 0.8014027791642615\n",
      "entropy 2 7 0.8017326328019181\n",
      "entropy 2 8 0.7993429640235803\n",
      "entropy 2 9 0.7993365844382534\n",
      "entropy 2 10 0.7986762973569136\n",
      "entropy 3 5 0.7988859410708992\n",
      "entropy 3 6 0.8039949801715425\n",
      "entropy 3 7 0.7995988462654102\n",
      "entropy 3 8 0.7977485094838969\n",
      "entropy 3 9 0.7990754632319031\n",
      "entropy 3 10 0.8004119863579\n",
      "entropy 4 5 0.7996558803345193\n",
      "entropy 4 6 0.8042667448254687\n",
      "entropy 4 7 0.8024004590806377\n",
      "entropy 4 8 0.8045565018844514\n",
      "entropy 4 9 0.8052263583437815\n",
      "entropy 4 10 0.8018738862544673\n",
      "entropy 5 5 0.7980019528240249\n",
      "entropy 5 6 0.8051488739766676\n",
      "entropy 5 7 0.8045474267700199\n",
      "entropy 5 8 0.802619025815366\n",
      "entropy 5 9 0.8026158360227026\n",
      "entropy 5 10 0.8046190258153659\n",
      "entropy 6 5 0.7974416630045076\n",
      "entropy 6 6 0.8045042259411502\n",
      "entropy 6 7 0.8019027787345026\n",
      "entropy 6 8 0.7999743777798487\n",
      "entropy 6 9 0.8006410444465153\n",
      "entropy 6 10 0.7993013315278551\n",
      "entropy 7 5 0.7977438693166494\n",
      "entropy 7 6 0.8027347476654786\n",
      "entropy 7 7 0.8034014143321452\n",
      "entropy 7 8 0.8007315578728148\n",
      "entropy 7 9 0.8020712707914754\n",
      "entropy 7 10 0.8000680809988117\n",
      "entropy 8 5 0.7966474372929714\n",
      "entropy 8 6 0.8042460568913071\n",
      "entropy 8 7 0.8029063439726472\n",
      "entropy 8 8 0.8015602514686597\n",
      "entropy 8 9 0.8015666310539867\n",
      "entropy 8 10 0.8015666310539867\n",
      "entropy 9 5 0.7961458162632111\n",
      "entropy 9 6 0.8035947726430605\n",
      "entropy 9 7 0.8022646291023905\n",
      "entropy 9 8 0.8029249161837304\n",
      "entropy 9 9 0.8022582495170635\n",
      "entropy 9 10 0.8042646291023905\n",
      "infogain_ratio 1 5 0.800276759188008\n",
      "infogain_ratio 1 6 0.7992997804669218\n",
      "infogain_ratio 1 7 0.7959525949021028\n",
      "infogain_ratio 1 8 0.8083764484150884\n",
      "infogain_ratio 1 9 0.8006539879632333\n",
      "infogain_ratio 1 10 0.8013493436089073\n",
      "infogain_ratio 2 5 0.7989370462693477\n",
      "infogain_ratio 2 6 0.7999728267189153\n",
      "infogain_ratio 2 7 0.7966192615687694\n",
      "infogain_ratio 2 8 0.8043700688297614\n",
      "infogain_ratio 2 9 0.7993078954592463\n",
      "infogain_ratio 2 10 0.8026922463202311\n",
      "infogain_ratio 3 5 0.7996069027286778\n",
      "infogain_ratio 3 6 0.7999696369262519\n",
      "infogain_ratio 3 7 0.7957346079734011\n",
      "infogain_ratio 3 8 0.8051989335105413\n",
      "infogain_ratio 3 9 0.7991279616674788\n",
      "infogain_ratio 3 10 0.7977148247429254\n",
      "infogain_ratio 4 5 0.7996069027286777\n",
      "infogain_ratio 4 6 0.8006363035929185\n",
      "infogain_ratio 4 7 0.7947877536257419\n",
      "infogain_ratio 4 8 0.8049187458295488\n",
      "infogain_ratio 4 9 0.7980438933544921\n",
      "infogain_ratio 4 10 0.7960925707840384\n",
      "infogain_ratio 5 5 0.7989370462693477\n",
      "infogain_ratio 5 6 0.8013061600522488\n",
      "infogain_ratio 5 7 0.7939031000303737\n",
      "infogain_ratio 5 8 0.8056822199653745\n",
      "infogain_ratio 5 9 0.8002503530059315\n",
      "infogain_ratio 5 10 0.7978291684997926\n",
      "infogain_ratio 6 5 0.7996069027286777\n",
      "infogain_ratio 6 6 0.8006363035929185\n",
      "infogain_ratio 6 7 0.7978346907776911\n",
      "infogain_ratio 6 8 0.8054610432440092\n",
      "infogain_ratio 6 9 0.8011072737333176\n",
      "infogain_ratio 6 10 0.7951187344593587\n",
      "infogain_ratio 7 5 0.7996069027286778\n",
      "infogain_ratio 7 6 0.7999696369262519\n",
      "infogain_ratio 7 7 0.7950900454803513\n",
      "infogain_ratio 7 8 0.7991585270143726\n",
      "infogain_ratio 7 9 0.7992165304556356\n",
      "infogain_ratio 7 10 0.7937546495503147\n",
      "infogain_ratio 8 5 0.8002051601426621\n",
      "infogain_ratio 8 6 0.800567894340236\n",
      "infogain_ratio 8 7 0.795685113101672\n",
      "infogain_ratio 8 8 0.7985823737740054\n",
      "infogain_ratio 8 9 0.793225789916131\n",
      "infogain_ratio 8 10 0.7910415067196472\n",
      "infogain_ratio 9 5 0.8002051601426621\n",
      "infogain_ratio 9 6 0.8003530972041979\n",
      "infogain_ratio 9 7 0.7960032683771312\n",
      "infogain_ratio 9 8 0.7959343648608898\n",
      "infogain_ratio 9 9 0.7949055056564649\n",
      "infogain_ratio 9 10 0.7910852873545435\n",
      "gini 1 5 0.7959571646707644\n",
      "gini 1 6 0.795218252601504\n",
      "gini 1 7 0.7983864547554633\n",
      "gini 1 8 0.7919873021416027\n",
      "gini 1 9 0.7946635381862597\n",
      "gini 1 10 0.7993397742309168\n",
      "gini 2 5 0.796623831337431\n",
      "gini 2 6 0.7965547757275008\n",
      "gini 2 7 0.7963768853774729\n",
      "gini 2 8 0.7973365844382534\n",
      "gini 2 9 0.7953333946455899\n",
      "gini 2 10 0.7986667279789234\n",
      "gini 3 5 0.7925117402534488\n",
      "gini 3 6 0.7971689098234637\n",
      "gini 3 7 0.7972341292834828\n",
      "gini 3 8 0.7946980726217893\n",
      "gini 3 9 0.7953679290811195\n",
      "gini 3 10 0.7947012624144529\n",
      "gini 4 5 0.7958894207665759\n",
      "gini 4 6 0.7978988380508776\n",
      "gini 4 7 0.7992289815915474\n",
      "gini 4 8 0.8007088738931716\n",
      "gini 4 9 0.7987088738931715\n",
      "gini 4 10 0.8007088738931714\n",
      "gini 5 5 0.7961052254209784\n",
      "gini 5 6 0.7966284563607967\n",
      "gini 5 7 0.8006380257387871\n",
      "gini 5 8 0.8006380257387871\n",
      "gini 5 9 0.802644405324114\n",
      "gini 5 10 0.7999745488647839\n",
      "gini 6 5 0.795454026715199\n",
      "gini 6 6 0.7979868270330078\n",
      "gini 6 7 0.8006630630776648\n",
      "gini 6 8 0.8013297297443316\n",
      "gini 6 9 0.7986534936996744\n",
      "gini 6 10 0.7993233501590045\n",
      "gini 7 5 0.7938278320726869\n",
      "gini 7 6 0.7988186248790484\n",
      "gini 7 7 0.799491671131042\n",
      "gini 7 8 0.7981551480050453\n",
      "gini 7 9 0.7988186248790485\n",
      "gini 7 10 0.8001583377977086\n",
      "gini 8 5 0.7942112068081653\n",
      "gini 8 6 0.8004636483600465\n",
      "gini 8 7 0.7991303150267132\n",
      "gini 8 8 0.7991303150267131\n",
      "gini 8 9 0.8004636483600465\n",
      "gini 8 10 0.7991303150267132\n",
      "gini 9 5 0.7957876499515457\n",
      "gini 9 6 0.7990805635275814\n",
      "gini 9 7 0.7984138968609148\n",
      "gini 9 8 0.7990805635275814\n",
      "gini 9 9 0.7990805635275815\n",
      "gini 9 10 0.7984170866535782\n",
      "0.8083764484150884 infogain_ratio 1 8\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the best DecisionTree(best val accuracy) that you can. You should choose some \n",
    "# hyper-parameters such as critertion, max_depth, and min_samples_in_leaf \n",
    "# according to the cross-validation result.\n",
    "# To reduce difficulty, you can use KFold here.\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "\n",
    "best_acc, best_min_samples_leaf, best_max_depth = 0, 0, 0\n",
    "best_method = \"\"\n",
    "for now_method in ['entropy', 'infogain_ratio', 'gini']:\n",
    "    for now_min_samples_leaf in range(1, 10):\n",
    "        for now_max_depth in range(5, 11):\n",
    "            dt = DecisionTree(criterion=now_method, max_depth=now_max_depth, min_samples_leaf=now_min_samples_leaf, sample_feature=False)\n",
    "            ave_acc = 0\n",
    "            for train_indice, valid_indice in kf.split(X, y):\n",
    "                X_train_fold, y_train_fold = X.loc[train_indice], y.loc[train_indice]\n",
    "                X_val_fold, y_val_fold = X.loc[valid_indice], y.loc[valid_indice]\n",
    "                dt.fit(X_train_fold, y_train_fold)\n",
    "                y_train_pred = dt.predict(X_train_fold) \n",
    "                y_valid_pred = dt.predict(X_val_fold)\n",
    "                ave_acc += accuracy(y_val_fold, y_valid_pred) * 0.7 + accuracy(y_train_fold, y_train_pred) * 0.3\n",
    "            ave_acc /= 5\n",
    "            print(now_method, now_min_samples_leaf, now_max_depth, ave_acc)\n",
    "            if ave_acc > best_acc:\n",
    "                best_acc = ave_acc\n",
    "                best_method = now_method\n",
    "                best_min_samples_leaf = now_min_samples_leaf\n",
    "                best_max_depth = now_max_depth\n",
    "    \n",
    "    \n",
    "# begin answer\n",
    "print (best_acc, best_method, best_min_samples_leaf, best_max_depth)\n",
    "# end answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.833810888252149\n",
      "Accuracy on test set: 0.8091603053435115\n"
     ]
    }
   ],
   "source": [
    "# report the accuracy on test set\n",
    "dt = DecisionTree(criterion=best_method, max_depth=best_max_depth, min_samples_leaf=best_min_samples_leaf, sample_feature=False)\n",
    "dt.fit(X, y)\n",
    "print(\"Accuracy on train set: {}\".format(accuracy(y, dt.predict(X))))\n",
    "print(\"Accuracy on test set: {}\".format(accuracy(y_test, dt.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(criterion='infogain_ratio', max_depth=8, min_samples_leaf=1, sample_feature=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Please implement the random forest model in **random_forest.py**. The PDF file provides some hints for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.8404966571155683\n",
      "Accuracy on test set: 0.816793893129771\n"
     ]
    }
   ],
   "source": [
    "from random_forest import RandomForest\n",
    "\n",
    "base_learner = DecisionTree(criterion='entropy', max_depth=5, min_samples_leaf=5, sample_feature=True)\n",
    "rf = RandomForest(base_learner=base_learner, n_estimator=100, seed=2020)\n",
    "rf.fit(X, y)\n",
    "\n",
    "y_train_pred = rf.predict(X)\n",
    "\n",
    "print(\"Accuracy on train set: {}\".format(accuracy(y, y_train_pred)))\n",
    "print(\"Accuracy on test set: {}\".format(accuracy(y_test, rf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.8691499522445081\n",
      "Accuracy on test set: 0.8015267175572519\n"
     ]
    }
   ],
   "source": [
    "from random_forest import RandomForest\n",
    "\n",
    "base_learner = DecisionTree(criterion='entropy', max_depth=8, min_samples_leaf=5, sample_feature=True)\n",
    "rf = RandomForest(base_learner=base_learner, n_estimator=100, seed=2020)\n",
    "rf.fit(X, y)\n",
    "\n",
    "y_train_pred = rf.predict(X)\n",
    "\n",
    "print(\"Accuracy on train set: {}\".format(accuracy(y, y_train_pred)))\n",
    "print(\"Accuracy on test set: {}\".format(accuracy(y_test, rf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  infogain_ratio 1 3 79.0561% 79.4415% 78.8909%\n",
      "  infogain_ratio 1 4 80.3463% 81.0650% 80.0383%\n",
      "  infogain_ratio 1 5 81.1680% 82.6885% 80.5163%\n",
      "  infogain_ratio 3 3 79.2239% 79.7756% 78.9875%\n",
      "  infogain_ratio 3 4 80.4344% 81.1365% 80.1335%\n",
      "  infogain_ratio 3 5 81.3780% 82.4975% 80.8982%\n",
      "  infogain_ratio 5 3 78.8731% 79.2740% 78.7013%\n",
      "  infogain_ratio 5 4 80.3886% 81.2083% 80.0374%\n",
      "  infogain_ratio 5 5 80.8788% 82.6168% 80.1340%\n",
      "  infogain_ratio 7 3 79.1757% 79.3937% 79.0823%\n",
      "  infogain_ratio 7 4 80.7734% 81.3755% 80.5154%\n",
      "  infogain_ratio 7 5 80.9483% 82.4020% 80.3254%\n",
      "  infogain_ratio 9 3 78.8872% 79.3221% 78.7008%\n",
      "  infogain_ratio 9 4 80.2936% 81.1126% 79.9426%\n",
      "  infogain_ratio 9 5 81.0966% 82.4497% 80.5167%\n",
      "            gini 1 3 81.6033% 82.1395% 81.3734%\n",
      "            gini 1 4 81.7639% 83.7870% 80.8968%\n",
      "            gini 1 5 81.8849% 85.5301% 80.3226%\n",
      "            gini 3 3 81.7229% 82.0918% 81.5648%\n",
      "            gini 3 4 82.0078% 83.9302% 81.1839%\n",
      "            gini 3 5 81.9693% 85.3629% 80.5149%\n",
      "            gini 5 3 81.6110% 82.1633% 81.3743%\n",
      "            gini 5 4 82.1390% 83.4766% 81.5657%\n",
      "            gini 5 5 82.0622% 85.0047% 80.8011%\n",
      "            gini 7 3 81.4696% 82.1394% 81.1825%\n",
      "            gini 7 4 82.1705% 83.3572% 81.6619%\n",
      "            gini 7 5 82.0432% 84.7182% 80.8968%\n",
      "            gini 9 3 81.4247% 82.2111% 81.0877%\n",
      "            gini 9 4 81.8359% 83.3571% 81.1839%\n",
      "            gini 9 5 82.0096% 84.3839% 80.9920%\n",
      "         entropy 1 3 81.5964% 82.1156% 81.3739%\n",
      "         entropy 1 4 81.8523% 83.8586% 80.9925%\n",
      "         entropy 1 5 81.9384% 85.4822% 80.4197%\n",
      "         entropy 3 3 81.5160% 82.0677% 81.2796%\n",
      "         entropy 3 4 81.8327% 83.5721% 81.0873%\n",
      "         entropy 3 5 81.9980% 85.4584% 80.5149%\n",
      "         entropy 5 3 81.6562% 82.0915% 81.4696%\n",
      "         entropy 5 4 82.1003% 83.5721% 81.4696%\n",
      "         entropy 5 5 81.8241% 85.1001% 80.4201%\n",
      "         entropy 7 3 81.3861% 82.3066% 80.9916%\n",
      "         entropy 7 4 82.1386% 83.4765% 81.5653%\n",
      "         entropy 7 5 81.8644% 84.7899% 80.6106%\n",
      "         entropy 9 3 81.3437% 82.1633% 80.9925%\n",
      "         entropy 9 4 82.0577% 83.4288% 81.4700%\n",
      "         entropy 9 5 81.8124% 84.1690% 80.8025%\n",
      "0.8217047728890462 gini 7 4\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the best RandomForest that you can. You should choose some \n",
    "# hyper-parameters such as max_depth, and min_samples_in_leaf \n",
    "# according to the cross-validation result.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "\n",
    "best_acc, best_min_samples_leaf, best_max_depth = 0, 0, 0\n",
    "best_method = \"\"\n",
    "for now_method in ['infogain_ratio', 'gini', 'entropy']:\n",
    "    for now_min_samples_leaf in range(1, 10, 2):\n",
    "        for now_max_depth in range(3, 6, 1):\n",
    "            base_learner = DecisionTree(criterion=now_method, max_depth=now_max_depth, min_samples_leaf=now_min_samples_leaf, sample_feature=True)\n",
    "            rf = RandomForest(base_learner=base_learner, n_estimator=100, seed=2020)\n",
    "            ave_valid_acc, ave_train_acc, ave_com_acc = 0, 0, 0\n",
    "            for train_indice, valid_indice in kf.split(X, y):\n",
    "                X_train_fold, y_train_fold = X.loc[train_indice], y.loc[train_indice]\n",
    "                X_val_fold, y_val_fold = X.loc[valid_indice], y.loc[valid_indice]\n",
    "                rf.fit(X_train_fold, y_train_fold)\n",
    "                y_train_pred = rf.predict(X_train_fold) \n",
    "                y_valid_pred = rf.predict(X_val_fold)\n",
    "                train_acc = accuracy(y_train_fold, y_train_pred)\n",
    "                valid_acc = accuracy(y_val_fold, y_valid_pred)\n",
    "                ave_train_acc += train_acc\n",
    "                ave_valid_acc += valid_acc\n",
    "                ave_com_acc += valid_acc * 0.7 + train_acc * 0.3\n",
    "                \n",
    "            ave_train_acc /= 5\n",
    "            ave_valid_acc /= 5\n",
    "            ave_com_acc /= 5\n",
    "            print(\"%16s %d %d %.4f%% %.4f%% %.4f%%\" % (now_method, now_min_samples_leaf, now_max_depth, ave_com_acc*100, ave_train_acc*100, ave_valid_acc*100))\n",
    "            if ave_com_acc > best_acc:\n",
    "                best_acc = ave_com_acc\n",
    "                best_method = now_method\n",
    "                best_min_samples_leaf = now_min_samples_leaf\n",
    "                best_max_depth = now_max_depth\n",
    "    \n",
    "    \n",
    "# begin answer\n",
    "print (best_acc, best_method, best_min_samples_leaf, best_max_depth)\n",
    "# end answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the accuracy on test set\n",
    "# k=100\n",
    "# begin answer\n",
    "# end answer\n",
    "rf.fit(X, y)\n",
    "print(\"Accuracy on train set: {}\".format(accuracy(y, rf.predict(X))))\n",
    "print(\"Accuracy on test set: {}\".format(accuracy(y_test, rf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost\n",
    "Please implement the adaboost model in **adaboost.py**. The PDF file provides some hints for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaboost import Adaboost\n",
    "\n",
    "base_learner = DecisionTree(criterion='entropy', max_depth=1, min_samples_leaf=1, sample_feature=False)\n",
    "ada = Adaboost(base_learner=base_learner, n_estimator=50, seed=2020)\n",
    "ada.fit(X, y)\n",
    "\n",
    "y_train_pred = ada.predict(X)\n",
    "\n",
    "print(\"Accuracy on train set: {}\".format(accuracy(y, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the best Adaboost that you can. You should choose some \n",
    "# hyper-parameters such as max_depth, and min_samples_in_leaf \n",
    "# according to the cross-validation result.\n",
    "# begin answer\n",
    "# end answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the accuracy on test set\n",
    "# begin answer\n",
    "# end answer\n",
    "ada.fit(X, y)\n",
    "print(\"Accuracy on train set: {}\".format(accuracy(y, ada.predict(X))))\n",
    "print(\"Accuracy on test set: {}\".format(accuracy(y_test, ada.predict(X_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
