{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. Please check the pdf file for more details.*\n",
    "\n",
    "In this exercise you will:\n",
    "    \n",
    "- implement the **forward** and **backward** operations for different layers in neural networks\n",
    "- implement a simple neural networks for classification\n",
    "\n",
    "Please note that **YOU CANNOT USE ANY MACHINE LEARNING PACKAGE SUCH AS SKLEARN** for any homework, unless you are asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic imports\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_data = sio.loadmat('digit_data.mat')\n",
    "X = digit_data['X']\n",
    "y = digit_data['y']\n",
    "_, num_cases = X.shape\n",
    "train_num_cases = num_cases * 4 // 5\n",
    "X = X.reshape((400, num_cases))\n",
    "X = X.transpose()\n",
    "# X has the shape of (number of samples, number of pixels)\n",
    "train_data = X[:train_num_cases,:]\n",
    "train_label = y[:, :train_num_cases]\n",
    "test_data = X[train_num_cases:, :]\n",
    "test_label = y[:, train_num_cases:]\n",
    "weights = {}\n",
    "weights['fully1_weight'] = np.random.randn(400, 25) / 400\n",
    "weights['fully1_bias'] = np.random.rand(25, 1) \n",
    "weights['fully2_weight'] = np.random.randn(25, 10) / 25\n",
    "weights['fully2_bias'] = np.random.rand(10, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. 1 loss:2.35, accuracy:0.09\n",
      "  1. 2 loss:2.32, accuracy:0.07\n",
      "  1. 3 loss:2.3, accuracy:0.13\n",
      "  1. 4 loss:2.33, accuracy:0.1\n",
      "  1. 5 loss:2.29, accuracy:0.11\n",
      "  1. 6 loss:2.28, accuracy:0.1\n",
      "  1. 7 loss:2.28, accuracy:0.08\n",
      "  1. 8 loss:2.28, accuracy:0.13\n",
      "  1. 9 loss:2.29, accuracy:0.09\n",
      "  1.10 loss:2.26, accuracy:0.16\n",
      "  1.11 loss:2.22, accuracy:0.22\n",
      "  1.12 loss:2.19, accuracy:0.25\n",
      "  1.13 loss:2.17, accuracy:0.27\n",
      "  1.14 loss:2.17, accuracy:0.28\n",
      "  1.15 loss:2.07, accuracy:0.38\n",
      "  1.16 loss:2.04, accuracy:0.44\n",
      "  1.17 loss:2.0, accuracy:0.44\n",
      "  1.18 loss:1.9, accuracy:0.52\n",
      "  1.19 loss:1.88, accuracy:0.47\n",
      "  1.20 loss:1.7, accuracy:0.59\n",
      "  1.21 loss:1.6, accuracy:0.62\n",
      "  1.22 loss:1.48, accuracy:0.64\n",
      "  1.23 loss:1.38, accuracy:0.7\n",
      "  1.24 loss:1.19, accuracy:0.77\n",
      "  1.25 loss:1.15, accuracy:0.75\n",
      "  1.26 loss:1.0, accuracy:0.8\n",
      "  1.27 loss:1.08, accuracy:0.73\n",
      "  1.28 loss:0.899, accuracy:0.8\n",
      "  1.29 loss:0.827, accuracy:0.82\n",
      "  1.30 loss:0.867, accuracy:0.75\n",
      "  1.31 loss:0.8, accuracy:0.74\n",
      "  1.32 loss:0.778, accuracy:0.71\n",
      "  1.33 loss:0.623, accuracy:0.76\n",
      "  1.34 loss:0.744, accuracy:0.78\n",
      "  1.35 loss:0.848, accuracy:0.71\n",
      "  1.36 loss:0.696, accuracy:0.82\n",
      "  1.37 loss:0.522, accuracy:0.85\n",
      "  1.38 loss:0.539, accuracy:0.85\n",
      "  1.39 loss:0.659, accuracy:0.82\n",
      "  1.40 loss:0.723, accuracy:0.8\n",
      "  2. 1 loss:0.607, accuracy:0.77\n",
      "  2. 2 loss:0.591, accuracy:0.81\n",
      "  2. 3 loss:0.517, accuracy:0.86\n",
      "  2. 4 loss:0.724, accuracy:0.81\n",
      "  2. 5 loss:0.655, accuracy:0.75\n",
      "  2. 6 loss:0.34, accuracy:0.9\n",
      "  2. 7 loss:0.557, accuracy:0.84\n",
      "  2. 8 loss:0.475, accuracy:0.81\n",
      "  2. 9 loss:0.405, accuracy:0.87\n",
      "  2.10 loss:0.671, accuracy:0.82\n",
      "  2.11 loss:0.54, accuracy:0.82\n",
      "  2.12 loss:0.796, accuracy:0.81\n",
      "  2.13 loss:0.581, accuracy:0.78\n",
      "  2.14 loss:0.663, accuracy:0.77\n",
      "  2.15 loss:0.264, accuracy:0.94\n",
      "  2.16 loss:0.467, accuracy:0.84\n",
      "  2.17 loss:0.627, accuracy:0.77\n",
      "  2.18 loss:0.673, accuracy:0.84\n",
      "  2.19 loss:0.445, accuracy:0.85\n",
      "  2.20 loss:0.428, accuracy:0.88\n",
      "  2.21 loss:0.418, accuracy:0.91\n",
      "  2.22 loss:0.644, accuracy:0.86\n",
      "  2.23 loss:0.431, accuracy:0.85\n",
      "  2.24 loss:0.381, accuracy:0.87\n",
      "  2.25 loss:0.337, accuracy:0.91\n",
      "  2.26 loss:0.355, accuracy:0.92\n",
      "  2.27 loss:0.655, accuracy:0.76\n",
      "  2.28 loss:0.471, accuracy:0.88\n",
      "  2.29 loss:0.409, accuracy:0.86\n",
      "  2.30 loss:0.366, accuracy:0.87\n",
      "  2.31 loss:0.43, accuracy:0.89\n",
      "  2.32 loss:0.407, accuracy:0.84\n",
      "  2.33 loss:0.502, accuracy:0.86\n",
      "  2.34 loss:0.442, accuracy:0.85\n",
      "  2.35 loss:0.53, accuracy:0.84\n",
      "  2.36 loss:0.408, accuracy:0.9\n",
      "  2.37 loss:0.32, accuracy:0.91\n",
      "  2.38 loss:0.365, accuracy:0.9\n",
      "  2.39 loss:0.287, accuracy:0.91\n",
      "  2.40 loss:0.461, accuracy:0.88\n",
      "  3. 1 loss:0.273, accuracy:0.92\n",
      "  3. 2 loss:0.465, accuracy:0.88\n",
      "  3. 3 loss:0.305, accuracy:0.9\n",
      "  3. 4 loss:0.45, accuracy:0.9\n",
      "  3. 5 loss:0.313, accuracy:0.91\n",
      "  3. 6 loss:0.19, accuracy:0.97\n",
      "  3. 7 loss:0.461, accuracy:0.88\n",
      "  3. 8 loss:0.296, accuracy:0.91\n",
      "  3. 9 loss:0.192, accuracy:0.92\n",
      "  3.10 loss:0.353, accuracy:0.9\n",
      "  3.11 loss:0.312, accuracy:0.89\n",
      "  3.12 loss:0.512, accuracy:0.88\n",
      "  3.13 loss:0.519, accuracy:0.83\n",
      "  3.14 loss:0.439, accuracy:0.86\n",
      "  3.15 loss:0.165, accuracy:0.92\n",
      "  3.16 loss:0.294, accuracy:0.91\n",
      "  3.17 loss:0.359, accuracy:0.86\n",
      "  3.18 loss:0.503, accuracy:0.88\n",
      "  3.19 loss:0.435, accuracy:0.84\n",
      "  3.20 loss:0.306, accuracy:0.89\n",
      "  3.21 loss:0.276, accuracy:0.91\n",
      "  3.22 loss:0.368, accuracy:0.9\n",
      "  3.23 loss:0.311, accuracy:0.88\n",
      "  3.24 loss:0.292, accuracy:0.92\n",
      "  3.25 loss:0.215, accuracy:0.94\n",
      "  3.26 loss:0.251, accuracy:0.92\n",
      "  3.27 loss:0.387, accuracy:0.83\n",
      "  3.28 loss:0.294, accuracy:0.93\n",
      "  3.29 loss:0.312, accuracy:0.9\n",
      "  3.30 loss:0.219, accuracy:0.94\n",
      "  3.31 loss:0.325, accuracy:0.91\n",
      "  3.32 loss:0.209, accuracy:0.95\n",
      "  3.33 loss:0.343, accuracy:0.89\n",
      "  3.34 loss:0.341, accuracy:0.9\n",
      "  3.35 loss:0.415, accuracy:0.91\n",
      "  3.36 loss:0.324, accuracy:0.91\n",
      "  3.37 loss:0.237, accuracy:0.92\n",
      "  3.38 loss:0.257, accuracy:0.95\n",
      "  3.39 loss:0.261, accuracy:0.93\n",
      "  3.40 loss:0.405, accuracy:0.89\n",
      "  4. 1 loss:0.196, accuracy:0.95\n",
      "  4. 2 loss:0.343, accuracy:0.91\n",
      "  4. 3 loss:0.214, accuracy:0.95\n",
      "  4. 4 loss:0.358, accuracy:0.9\n",
      "  4. 5 loss:0.272, accuracy:0.91\n",
      "  4. 6 loss:0.125, accuracy:0.97\n",
      "  4. 7 loss:0.381, accuracy:0.89\n",
      "  4. 8 loss:0.202, accuracy:0.97\n",
      "  4. 9 loss:0.162, accuracy:0.95\n",
      "  4.10 loss:0.331, accuracy:0.9\n",
      "  4.11 loss:0.246, accuracy:0.89\n",
      "  4.12 loss:0.37, accuracy:0.9\n",
      "  4.13 loss:0.388, accuracy:0.87\n",
      "  4.14 loss:0.393, accuracy:0.91\n",
      "  4.15 loss:0.142, accuracy:0.93\n",
      "  4.16 loss:0.257, accuracy:0.92\n",
      "  4.17 loss:0.28, accuracy:0.9\n",
      "  4.18 loss:0.393, accuracy:0.89\n",
      "  4.19 loss:0.412, accuracy:0.83\n",
      "  4.20 loss:0.261, accuracy:0.93\n",
      "  4.21 loss:0.256, accuracy:0.92\n",
      "  4.22 loss:0.25, accuracy:0.92\n",
      "  4.23 loss:0.264, accuracy:0.94\n",
      "  4.24 loss:0.246, accuracy:0.9\n",
      "  4.25 loss:0.171, accuracy:0.94\n",
      "  4.26 loss:0.198, accuracy:0.96\n",
      "  4.27 loss:0.302, accuracy:0.89\n",
      "  4.28 loss:0.239, accuracy:0.94\n",
      "  4.29 loss:0.295, accuracy:0.92\n",
      "  4.30 loss:0.205, accuracy:0.94\n",
      "  4.31 loss:0.249, accuracy:0.94\n",
      "  4.32 loss:0.197, accuracy:0.95\n",
      "  4.33 loss:0.314, accuracy:0.88\n",
      "  4.34 loss:0.261, accuracy:0.93\n",
      "  4.35 loss:0.367, accuracy:0.94\n",
      "  4.36 loss:0.298, accuracy:0.92\n",
      "  4.37 loss:0.203, accuracy:0.93\n",
      "  4.38 loss:0.249, accuracy:0.95\n",
      "  4.39 loss:0.217, accuracy:0.94\n",
      "  4.40 loss:0.358, accuracy:0.92\n",
      "  5. 1 loss:0.168, accuracy:0.94\n",
      "  5. 2 loss:0.317, accuracy:0.9\n",
      "  5. 3 loss:0.187, accuracy:0.98\n",
      "  5. 4 loss:0.315, accuracy:0.92\n",
      "  5. 5 loss:0.255, accuracy:0.93\n",
      "  5. 6 loss:0.102, accuracy:0.99\n",
      "  5. 7 loss:0.32, accuracy:0.9\n",
      "  5. 8 loss:0.152, accuracy:0.97\n",
      "  5. 9 loss:0.159, accuracy:0.94\n",
      "  5.10 loss:0.324, accuracy:0.93\n",
      "  5.11 loss:0.215, accuracy:0.92\n",
      "  5.12 loss:0.319, accuracy:0.93\n",
      "  5.13 loss:0.325, accuracy:0.89\n",
      "  5.14 loss:0.372, accuracy:0.91\n",
      "  5.15 loss:0.127, accuracy:0.95\n",
      "  5.16 loss:0.24, accuracy:0.92\n",
      "  5.17 loss:0.24, accuracy:0.91\n",
      "  5.18 loss:0.347, accuracy:0.92\n",
      "  5.19 loss:0.359, accuracy:0.88\n",
      "  5.20 loss:0.237, accuracy:0.94\n",
      "  5.21 loss:0.233, accuracy:0.93\n",
      "  5.22 loss:0.214, accuracy:0.93\n",
      "  5.23 loss:0.254, accuracy:0.94\n",
      "  5.24 loss:0.228, accuracy:0.91\n",
      "  5.25 loss:0.148, accuracy:0.96\n",
      "  5.26 loss:0.153, accuracy:0.97\n",
      "  5.27 loss:0.249, accuracy:0.92\n",
      "  5.28 loss:0.2, accuracy:0.97\n",
      "  5.29 loss:0.269, accuracy:0.93\n",
      "  5.30 loss:0.198, accuracy:0.95\n",
      "  5.31 loss:0.232, accuracy:0.94\n",
      "  5.32 loss:0.208, accuracy:0.95\n",
      "  5.33 loss:0.305, accuracy:0.91\n",
      "  5.34 loss:0.229, accuracy:0.93\n",
      "  5.35 loss:0.324, accuracy:0.92\n",
      "  5.36 loss:0.258, accuracy:0.93\n",
      "  5.37 loss:0.176, accuracy:0.93\n",
      "  5.38 loss:0.213, accuracy:0.97\n",
      "  5.39 loss:0.197, accuracy:0.96\n",
      "  5.40 loss:0.322, accuracy:0.9\n",
      "  6. 1 loss:0.145, accuracy:0.95\n",
      "  6. 2 loss:0.279, accuracy:0.91\n",
      "  6. 3 loss:0.178, accuracy:0.96\n",
      "  6. 4 loss:0.268, accuracy:0.92\n",
      "  6. 5 loss:0.254, accuracy:0.95\n",
      "  6. 6 loss:0.0962, accuracy:0.98\n",
      "  6. 7 loss:0.267, accuracy:0.91\n",
      "  6. 8 loss:0.117, accuracy:0.98\n",
      "  6. 9 loss:0.121, accuracy:0.95\n",
      "  6.10 loss:0.262, accuracy:0.93\n",
      "  6.11 loss:0.179, accuracy:0.93\n",
      "  6.12 loss:0.304, accuracy:0.93\n",
      "  6.13 loss:0.305, accuracy:0.9\n",
      "  6.14 loss:0.363, accuracy:0.92\n",
      "  6.15 loss:0.0998, accuracy:0.97\n",
      "  6.16 loss:0.203, accuracy:0.95\n",
      "  6.17 loss:0.204, accuracy:0.92\n",
      "  6.18 loss:0.324, accuracy:0.93\n",
      "  6.19 loss:0.307, accuracy:0.9\n",
      "  6.20 loss:0.204, accuracy:0.95\n",
      "  6.21 loss:0.192, accuracy:0.94\n",
      "  6.22 loss:0.199, accuracy:0.93\n",
      "  6.23 loss:0.248, accuracy:0.94\n",
      "  6.24 loss:0.228, accuracy:0.9\n",
      "  6.25 loss:0.141, accuracy:0.95\n",
      "  6.26 loss:0.133, accuracy:0.97\n",
      "  6.27 loss:0.245, accuracy:0.92\n",
      "  6.28 loss:0.154, accuracy:0.97\n",
      "  6.29 loss:0.218, accuracy:0.96\n",
      "  6.30 loss:0.163, accuracy:0.95\n",
      "  6.31 loss:0.214, accuracy:0.94\n",
      "  6.32 loss:0.204, accuracy:0.97\n",
      "  6.33 loss:0.308, accuracy:0.89\n",
      "  6.34 loss:0.228, accuracy:0.94\n",
      "  6.35 loss:0.327, accuracy:0.92\n",
      "  6.36 loss:0.233, accuracy:0.95\n",
      "  6.37 loss:0.152, accuracy:0.93\n",
      "  6.38 loss:0.187, accuracy:0.96\n",
      "  6.39 loss:0.173, accuracy:0.97\n",
      "  6.40 loss:0.289, accuracy:0.91\n",
      "  7. 1 loss:0.113, accuracy:0.97\n",
      "  7. 2 loss:0.221, accuracy:0.92\n",
      "  7. 3 loss:0.142, accuracy:0.97\n",
      "  7. 4 loss:0.23, accuracy:0.95\n",
      "  7. 5 loss:0.25, accuracy:0.95\n",
      "  7. 6 loss:0.1, accuracy:0.98\n",
      "  7. 7 loss:0.247, accuracy:0.93\n",
      "  7. 8 loss:0.101, accuracy:0.97\n",
      "  7. 9 loss:0.0935, accuracy:0.97\n",
      "  7.10 loss:0.171, accuracy:0.94\n",
      "  7.11 loss:0.156, accuracy:0.95\n",
      "  7.12 loss:0.266, accuracy:0.93\n",
      "  7.13 loss:0.261, accuracy:0.92\n",
      "  7.14 loss:0.348, accuracy:0.92\n",
      "  7.15 loss:0.0902, accuracy:0.98\n",
      "  7.16 loss:0.162, accuracy:0.96\n",
      "  7.17 loss:0.173, accuracy:0.92\n",
      "  7.18 loss:0.288, accuracy:0.91\n",
      "  7.19 loss:0.261, accuracy:0.92\n",
      "  7.20 loss:0.18, accuracy:0.95\n",
      "  7.21 loss:0.154, accuracy:0.96\n",
      "  7.22 loss:0.175, accuracy:0.94\n",
      "  7.23 loss:0.218, accuracy:0.95\n",
      "  7.24 loss:0.197, accuracy:0.91\n",
      "  7.25 loss:0.119, accuracy:0.96\n",
      "  7.26 loss:0.129, accuracy:0.97\n",
      "  7.27 loss:0.252, accuracy:0.9\n",
      "  7.28 loss:0.145, accuracy:0.98\n",
      "  7.29 loss:0.188, accuracy:0.97\n",
      "  7.30 loss:0.129, accuracy:0.96\n",
      "  7.31 loss:0.176, accuracy:0.95\n",
      "  7.32 loss:0.146, accuracy:0.97\n",
      "  7.33 loss:0.274, accuracy:0.92\n",
      "  7.34 loss:0.204, accuracy:0.95\n",
      "  7.35 loss:0.317, accuracy:0.94\n",
      "  7.36 loss:0.211, accuracy:0.95\n",
      "  7.37 loss:0.155, accuracy:0.94\n",
      "  7.38 loss:0.155, accuracy:0.96\n",
      "  7.39 loss:0.162, accuracy:0.95\n",
      "  7.40 loss:0.237, accuracy:0.92\n",
      "  8. 1 loss:0.0889, accuracy:0.97\n",
      "  8. 2 loss:0.161, accuracy:0.97\n",
      "  8. 3 loss:0.11, accuracy:0.97\n",
      "  8. 4 loss:0.189, accuracy:0.96\n",
      "  8. 5 loss:0.215, accuracy:0.94\n",
      "  8. 6 loss:0.0864, accuracy:0.99\n",
      "  8. 7 loss:0.234, accuracy:0.92\n",
      "  8. 8 loss:0.105, accuracy:0.97\n",
      "  8. 9 loss:0.0911, accuracy:0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.10 loss:0.138, accuracy:0.96\n",
      "  8.11 loss:0.146, accuracy:0.95\n",
      "  8.12 loss:0.217, accuracy:0.96\n",
      "  8.13 loss:0.182, accuracy:0.92\n",
      "  8.14 loss:0.287, accuracy:0.94\n",
      "  8.15 loss:0.0876, accuracy:0.97\n",
      "  8.16 loss:0.149, accuracy:0.96\n",
      "  8.17 loss:0.141, accuracy:0.95\n",
      "  8.18 loss:0.24, accuracy:0.93\n",
      "  8.19 loss:0.217, accuracy:0.94\n",
      "  8.20 loss:0.151, accuracy:0.96\n",
      "  8.21 loss:0.125, accuracy:0.97\n",
      "  8.22 loss:0.162, accuracy:0.92\n",
      "  8.23 loss:0.188, accuracy:0.96\n",
      "  8.24 loss:0.15, accuracy:0.95\n",
      "  8.25 loss:0.0995, accuracy:0.96\n",
      "  8.26 loss:0.104, accuracy:0.98\n",
      "  8.27 loss:0.195, accuracy:0.95\n",
      "  8.28 loss:0.125, accuracy:0.99\n",
      "  8.29 loss:0.169, accuracy:0.97\n",
      "  8.30 loss:0.12, accuracy:0.96\n",
      "  8.31 loss:0.165, accuracy:0.95\n",
      "  8.32 loss:0.103, accuracy:0.97\n",
      "  8.33 loss:0.207, accuracy:0.94\n",
      "  8.34 loss:0.175, accuracy:0.97\n",
      "  8.35 loss:0.272, accuracy:0.94\n",
      "  8.36 loss:0.179, accuracy:0.96\n",
      "  8.37 loss:0.16, accuracy:0.94\n",
      "  8.38 loss:0.126, accuracy:0.97\n",
      "  8.39 loss:0.155, accuracy:0.95\n",
      "  8.40 loss:0.199, accuracy:0.95\n",
      "  9. 1 loss:0.0632, accuracy:0.98\n",
      "  9. 2 loss:0.124, accuracy:0.98\n",
      "  9. 3 loss:0.0906, accuracy:0.98\n",
      "  9. 4 loss:0.158, accuracy:0.98\n",
      "  9. 5 loss:0.197, accuracy:0.93\n",
      "  9. 6 loss:0.084, accuracy:0.99\n",
      "  9. 7 loss:0.181, accuracy:0.93\n",
      "  9. 8 loss:0.0762, accuracy:0.98\n",
      "  9. 9 loss:0.0861, accuracy:0.99\n",
      "  9.10 loss:0.134, accuracy:0.96\n",
      "  9.11 loss:0.121, accuracy:0.97\n",
      "  9.12 loss:0.197, accuracy:0.97\n",
      "  9.13 loss:0.139, accuracy:0.95\n",
      "  9.14 loss:0.213, accuracy:0.94\n",
      "  9.15 loss:0.065, accuracy:0.98\n",
      "  9.16 loss:0.138, accuracy:0.95\n",
      "  9.17 loss:0.12, accuracy:0.96\n",
      "  9.18 loss:0.214, accuracy:0.95\n",
      "  9.19 loss:0.188, accuracy:0.94\n",
      "  9.20 loss:0.134, accuracy:0.96\n",
      "  9.21 loss:0.108, accuracy:0.96\n",
      "  9.22 loss:0.124, accuracy:0.96\n",
      "  9.23 loss:0.15, accuracy:0.97\n",
      "  9.24 loss:0.136, accuracy:0.95\n",
      "  9.25 loss:0.0904, accuracy:0.97\n",
      "  9.26 loss:0.0942, accuracy:0.97\n",
      "  9.27 loss:0.137, accuracy:0.96\n",
      "  9.28 loss:0.1, accuracy:0.98\n",
      "  9.29 loss:0.152, accuracy:0.96\n",
      "  9.30 loss:0.106, accuracy:0.97\n",
      "  9.31 loss:0.14, accuracy:0.95\n",
      "  9.32 loss:0.0902, accuracy:0.99\n",
      "  9.33 loss:0.193, accuracy:0.95\n",
      "  9.34 loss:0.162, accuracy:0.96\n",
      "  9.35 loss:0.269, accuracy:0.93\n",
      "  9.36 loss:0.149, accuracy:0.97\n",
      "  9.37 loss:0.142, accuracy:0.95\n",
      "  9.38 loss:0.0983, accuracy:0.98\n",
      "  9.39 loss:0.134, accuracy:0.96\n",
      "  9.40 loss:0.17, accuracy:0.97\n",
      " 10. 1 loss:0.0501, accuracy:0.99\n",
      " 10. 2 loss:0.114, accuracy:0.99\n",
      " 10. 3 loss:0.0756, accuracy:0.99\n",
      " 10. 4 loss:0.142, accuracy:0.97\n",
      " 10. 5 loss:0.161, accuracy:0.95\n",
      " 10. 6 loss:0.0674, accuracy:0.99\n",
      " 10. 7 loss:0.15, accuracy:0.94\n",
      " 10. 8 loss:0.0701, accuracy:0.98\n",
      " 10. 9 loss:0.0916, accuracy:0.98\n",
      " 10.10 loss:0.141, accuracy:0.95\n",
      " 10.11 loss:0.0916, accuracy:0.99\n",
      " 10.12 loss:0.168, accuracy:0.97\n",
      " 10.13 loss:0.139, accuracy:0.96\n",
      " 10.14 loss:0.198, accuracy:0.92\n",
      " 10.15 loss:0.0643, accuracy:0.99\n",
      " 10.16 loss:0.137, accuracy:0.95\n",
      " 10.17 loss:0.12, accuracy:0.96\n",
      " 10.18 loss:0.204, accuracy:0.94\n",
      " 10.19 loss:0.17, accuracy:0.94\n",
      " 10.20 loss:0.106, accuracy:0.96\n",
      " 10.21 loss:0.108, accuracy:0.96\n",
      " 10.22 loss:0.106, accuracy:0.97\n",
      " 10.23 loss:0.134, accuracy:0.98\n",
      " 10.24 loss:0.13, accuracy:0.96\n",
      " 10.25 loss:0.0921, accuracy:0.96\n",
      " 10.26 loss:0.0826, accuracy:0.99\n",
      " 10.27 loss:0.119, accuracy:0.97\n",
      " 10.28 loss:0.0846, accuracy:0.98\n",
      " 10.29 loss:0.147, accuracy:0.96\n",
      " 10.30 loss:0.0917, accuracy:0.97\n",
      " 10.31 loss:0.123, accuracy:0.95\n",
      " 10.32 loss:0.0824, accuracy:0.99\n",
      " 10.33 loss:0.18, accuracy:0.96\n",
      " 10.34 loss:0.153, accuracy:0.96\n",
      " 10.35 loss:0.26, accuracy:0.93\n",
      " 10.36 loss:0.141, accuracy:0.97\n",
      " 10.37 loss:0.136, accuracy:0.96\n",
      " 10.38 loss:0.0828, accuracy:0.98\n",
      " 10.39 loss:0.119, accuracy:0.96\n",
      " 10.40 loss:0.169, accuracy:0.96\n"
     ]
    }
   ],
   "source": [
    "# training setting\n",
    "weight_inc = {}\n",
    "for name in ('fully1_weight', 'fully1_bias', 'fully2_weight', 'fully2_bias'):\n",
    "    weight_inc[name] = np.zeros(weights[name].shape)\n",
    "batch_size = 100\n",
    "max_epoch = 10\n",
    "momW = 0.9\n",
    "wc = 0.0005\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training iterations\n",
    "from get_new_weight_inc import get_new_weight_inc\n",
    "from feedforward_backprop import feedforward_backprop\n",
    "\n",
    "XX = []\n",
    "YY = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    cnt = 0\n",
    "    ave = 0\n",
    "    for i in range(math.ceil(train_num_cases/batch_size)):\n",
    "        data = train_data[i * batch_size:min((i + 1) * batch_size, train_num_cases), :]\n",
    "        label = train_label[:, i * batch_size:min((i + 1) * batch_size, train_num_cases)]\n",
    "        # The feedforward and backpropgation processes\n",
    "        loss, accuracy, gradients = feedforward_backprop(data, label, weights)\n",
    "        print('{:3}.{:2} loss:{:.3}, accuracy:{}'.format(epoch + 1, i + 1, loss, accuracy))\n",
    "        ave += accuracy\n",
    "        cnt += 1\n",
    "        # Updating weights\n",
    "        for name in ('fully1_weight', 'fully1_bias', 'fully2_weight', 'fully2_bias'):\n",
    "            weight_inc[name] = get_new_weight_inc(weight_inc[name], weights[name], momW, wc, learning_rate, gradients[name + '_grad'])\n",
    "            weights[name] += weight_inc[name]\n",
    "    XX.append(epoch+1)\n",
    "    YY.append(ave / cnt)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.241, accuracy:0.927\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(XX, YY, \"-^\")\n",
    "plt.show()\n",
    "loss, accuracy, _ = feedforward_backprop(test_data, test_label, weights)\n",
    "print('loss:{:.3}, accuracy:{}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
